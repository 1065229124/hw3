---
title: "Homework Assignment 3"
author: "Johnny JI"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
library(knitr)
library(tidyverse)
library(tidymodels)
library(data.table)
library(corrplot)
library(discrim)
library(klaR)
library(dplyr)
library(corrr)
set.seed(891)
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
options(digits = 4)
```

##Load the data

```{r}
titanic<- read.csv("data/titanic.csv")
titanic$survived <- as.factor(titanic$survived)
titanic$pclass <- as.factor(titanic$pclass)
head(titanic)
```


### Question 1

```{r}
titanic_split <- initial_split(titanic, prop = 0.80,strata = "survived")
titanic_train <- training(titanic_split)
titanic_test <- testing(titanic_split)
# checking the missing value
print(sapply(titanic_train, function(x) sum(is.na(x))))
```

The goal to use stratified sampling stratified sampling is to make sure  we have proper representation of the entire population being studied

### Question 2
```{r}
titanic_train %>% 
 ggplot(aes(x = survived)) +
 geom_bar()
```

We can see most people are not survived.

### Question 3
```{r}
#correlation matrix
titanic_train_cor = titanic_train[ , !(names(titanic_train) %in% c("cabin", "embarked"))] %>% copy()
titanic_train_cor = titanic_train_cor %>% drop_na()
corrplot(cor(titanic_train_cor[ , sapply(titanic_train_cor, is.numeric)]), 
         method="number", type="lower")

#visualization matrix
cor_titanic <- select_if(titanic_train_cor,is.numeric) %>% correlate()
rplot(cor_titanic)
```



We can find that, negative correlation between the sib_sp and age, and positive correlation between the parch and sib_sp.


### Question 4
```{r}
titanic_recipe = recipe(survived ~ pclass + age+ sex +sib_sp + parch + fare, data=titanic_train) %>%
 step_impute_linear(age) %>%
 step_dummy(all_nominal_predictors()) %>%
 step_interact( ~ starts_with("sex"):fare+ age:fare)
```


### Question 5
```{r}
log_model = logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")
log_workflow = workflow() %>%
  add_model(log_model) %>%
  add_recipe(titanic_recipe)
log_fit<- fit(log_workflow, titanic_train)
```

### Question 6
```{r}
lda_model = discrim_linear() %>%
  set_engine("MASS") %>%
  set_mode("classification")
lda_workflow = workflow() %>%
  add_model(lda_model) %>%
  add_recipe(titanic_recipe)
lda_fit <- fit(lda_workflow, titanic_train)
```


### Question 7
```{r}
qda_model = discrim_quad() %>%
  set_engine("MASS") %>%
  set_mode("classification")
qda_workflow = workflow() %>%
  add_model(qda_model) %>%
  add_recipe(titanic_recipe)
qda_fit <- fit(qda_workflow, titanic_train)
```

### Question 8
```{r}
nb_mod <- naive_Bayes() %>% 
 set_mode("classification") %>% 
 set_engine("klaR") %>% 
 set_args(usekernel = FALSE) 
nb_workflow <- workflow() %>% 
 add_model(nb_mod) %>% 
 add_recipe(titanic_recipe)
nb_fit <- fit(nb_workflow, titanic_train)
```


### Question 9
```{r}
bound_train_data = bind_cols(predict(log_fit, titanic_train),
                             predict(lda_fit, titanic_train),
                             predict(qda_fit, titanic_train),
                             predict(nb_fit, titanic_train),
                             titanic_train$survived)
colnames(bound_train_data) = c("log Predict", "lda Predict", "qda Predict",
                               "NB Predict", "Truth")
```


```{r}
#The logistic model accuracy
print(augment(log_fit, new_data = titanic_train) %>%
 accuracy(truth = survived, estimate = .pred_class))

```
```{r}
#The linear discriminant analysis model accuracy
print(augment(lda_fit, new_data = titanic_train) %>%
 accuracy(truth = survived, estimate = .pred_class))
```
```{r}

#The quadratic discriminant analysis model accuracy
print( augment(qda_fit, new_data = titanic_train) %>%
 accuracy(truth = survived, estimate = .pred_class))
```

```{r}
#The native bayesian model accuracy
print( augment(nb_fit, new_data = titanic_train) %>%
 accuracy(truth = survived, estimate = .pred_class))
```

Therefore, logicstic model has the highest accuracy of 0.815


### Question 10
```{r}
bound_test_data = bind_cols(predict(log_fit, titanic_test),
                            titanic_test$survived)
colnames(bound_test_data) = c("log Predict", "True")
print(accuracy(bound_test_data, 
               truth="True", estimate="log Predict")$.estimate)
```
The logistic regression model has  about 81% accuracy on the test set.

```{r}
conf_mat(bound_test_data, truth="True", estimate="log Predict")
```
```{r}
roc = log_fit %>%
  predict(new_data=titanic_test, type="prob") %>%
  bind_cols(titanic_test) %>%
  roc_curve(survived, .pred_Yes, event_level="second")
autoplot(roc)
```
```{r}
auc = log_fit %>%
  predict(new_data=titanic_test, type="prob") %>%
  bind_cols(titanic_test) %>%
  roc_auc(survived, .pred_Yes, event_level="second")
print(auc$.estimate)
```
 We got around 81.01% train and  85.11% test accuracy. The slight different may caused by when we split the data, more data are used to train. In conclusion, we can tell that the this model is good for predict the data, 


### Question 11


$z = logit(p) = log \dfrac{p}{1-p} $

$e^z = \dfrac{p}{1-p}$

$1 + e^z = \dfrac{1-p}{1-p} + \dfrac{p}{1-p} = \dfrac{1}{1-p}$

$\dfrac{1}{1 + e^z} = 1 - p$

Thus we get that 

$p = 1 - \dfrac{1}{1 + e^z} = \dfrac{e^z}{1 + e^z}$


### Question 12


When increase by 2, we get that 

$z= \beta_0 +\beta_1(x_1 +2)$


which we know that 

$\beta_0 +\beta_1x_1 =log(\dfrac {p(z)}{1-p(z)})=\dfrac{e^{\beta_0 + \beta1x1}}{1+e^{\beta_0 + \beta1x1}}$

Then 

$logstic(z)=\dfrac{e^{\beta_0 + \beta1x1} e^{2\beta1}}{1+e^{\beta_0 + \beta1x1} e^{2\beta1}}$


If$\beta_1$ is negative then increasing$x_1$ will be associated with decreasing $p$.$p$ approach$0$ as$x_1$ approaches$\infty$ , and$p$ approach$1$ as $x_1$
 approaches$-\infty$ .














